## ðŸ“… Learning Progress

1. **[Day 1 â€“ NumPy](Day_01_Numpy.ipynb)**  
   Introduction to NumPy, arrays, indexing, slicing, and basic numerical operations.

2. **[Day 2 â€“ Pandas](Day_02_Pandas.ipynb)**  
   Working with Pandas DataFrames, Series, data selection, filtering, and basic operations.

3. **[Day 3 â€“ Data Preprocessing](Day_03_Data_Preprocessing.ipynb)**  
   Handling missing values, encoding categorical data, feature scaling, and splitting datasets.

4. **[Day 4 â€“ Linear Model & Metrics](Day_04_Linear_Model_and_Metrics.ipynb)**  
   Building linear regression models, calculating accuracy, MAE, MSE, RMSE.

5. **[Day 5 â€“ Decision Tree](Day_05_Decision_Tree.ipynb)**  
   Decision Tree basics, Gini index, entropy, and visualizing trees.

6. **[Day 6 â€“ Grid Search & Hyperparameter Tuning](Day_06_GridSearch_Hyperparameter_Tuning.ipynb)**  
   Finding the best parameters for a model using GridSearchCV.

7. **[Day 7 â€“ Logistic Regression & Model Evaluation](Day_07_Logistic_Regression_and_Model_Evaluation.ipynb)**  
   Logistic regression for classification, confusion matrix, precision, recall, F1-score.

8. **[Day 8 â€“ Cross Validation](Day_08_Cross_Validation.ipynb)**  
   Understanding k-fold cross-validation and evaluating model stability.

9. **[Day 9 â€“ Grid Search](Day_09_gridsearchcv_decisiontree.ipynb)**  
   Understanding k-fold grid search and hypertuning the model.
   
10. **[Day 10 - Feature importance](Day_10_feature_importance_selection.ipynb)**  
   Understand and Learned the heatmap and reduce the less importent features.

11. **[Day 11 - Feature Selection](Day_11_RF_FeatureSelection.ipynb)**  
   Learned to reduce the less importent feactures for saving time&space complexty

12. **[Day 12 - Pipeline with PCA](Day_12_pipeline_with_pca.ipynb)**  
   Learned PCA for dimensionality reduction and how to use Pipelines to avoid data leakage.

13. **[Day 13 - Pipeline with Slector and CrossValidation Strategies](Day_13_00_Pipeline_with_slector.ipynb)**  
     Compared KFold, StratifiedKFold, and ShuffleSplit for cross-validation.

14. **[Day 14 - Nested CV's](Day_14_nested_CV_.ipynb)**  
   Practiced learning nested cv's for redusing the model geting lucky chances.

15. **[Day 15 - SVC and Learning validation curves](Day_15_00_svc_and_Learning_validationcurves.ipynb)**  
   Practiced learning curves & validation curves to analyze model bias/variance,
   Studied classification metrics (precision, recall, F1-score) with medical dataset focus

16. **[Day 16 - Class wight and SMOTE](Day_16_class_wight_&_SMOTE.ipynb)**  
  Explored imbalanced datasets and how to handle them with class_weight in classifiers
---
